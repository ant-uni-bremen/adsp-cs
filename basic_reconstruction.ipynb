{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Compressed Sesing Reconcstruction\n",
    "## Introduction\n",
    "This notebook shows basic examples for compressed sensing reconstruction problems with different algorithms.\n",
    "\n",
    "## Basic reconstruction idea with norm relaxation\n",
    "\n",
    "Assum the basic $l_0$ minimzation problem from CS:\n",
    "\n",
    "$$\\min_{\\mathbf{x}\\in\\mathbb{R}}\\lVert \\mathbf{x} \\rVert_0\\quad\\mathrm{s.t.}\\quad \\lVert \\mathbf{y}-\\mathbf{A}\\mathbf{x}\\rVert_2< \\epsilon$$\n",
    "\n",
    "Then, we can relax the $l_0$ \"norm\" to another norm like the convex $l_1$ norm:\n",
    "\n",
    "$$\\min_{\\mathbf{x}\\in\\mathbb{R}}\\lVert \\mathbf{x} \\rVert_1\\quad\\mathrm{s.t.}\\quad \\lVert \\mathbf{y}-\\mathbf{A}\\mathbf{x}\\rVert_2 < \\epsilon$$\n",
    "\n",
    "In the noiseless case, the constraint simplifies to $\\mathbf{A}\\mathbf{x}=\\mathbf{y}$. Thus, the solution is at the intersection of the hyperplanes defined by the equation system and the scales unit sphere in the chosen norm. The following code illustrates this with a 2D example. Feasible $\\mathbf{x}$ that solve $\\mathbf{A}\\mathbf{x}=\\mathbf{y}$ are on the blue line. This line then touches the scaled unit sphere (green) of different norms at different points (red). Note, that it only leads to a sparse solution for the $l_1$ norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "from numpy import linspace\n",
    "from math import sqrt\n",
    "\n",
    "def scale_plot_size(factor=1.5):\n",
    "    import matplotlib as mpl\n",
    "    default_dpi = mpl.rcParamsDefault['figure.dpi']\n",
    "    mpl.rcParams['figure.dpi'] = default_dpi*factor\n",
    "\n",
    "scale_plot_size(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da697fc10f5d4a059c4ee6e746416f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6f2c514611446eb3a470e737d20d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Play(value=0, description='Press play', interval=50), IntSlider(value=0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axs = plt.subplots(1, 4, sharey=True)\n",
    "fig.suptitle(\"Illustration of norm effects on the solution\")\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(3)\n",
    "#fig.set_tight_layout(True)\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = False\n",
    "fig.canvas.resizable = False\n",
    "\n",
    "anno_list=[]\n",
    "lines_list=[]\n",
    "sp_space=[]\n",
    "\n",
    "title_list=('$l_0$ norm', '$l_1$ norm', '$l_2$ norm', '$l_\\infty$ norm')\n",
    "pnt_list=((0,0.5),(0,0.5),(1/5,2/5),(1/3,1/3))\n",
    "annos=('(0,0.5)','(0,0.5)','(1/5,2/5)','(1/3,1/3)')\n",
    "\n",
    "x1 = linspace(-1,1,10)\n",
    "\n",
    "sp_space.append(linspace(0.05,0.5,100))\n",
    "sp_space.append(linspace(0.05,0.5,100))\n",
    "sp_space.append(linspace(0.05,1/sqrt(5),100))\n",
    "sp_space.append(linspace(0.05,1/3,100))\n",
    "\n",
    "axs[0].set_ylabel('$x_2$')\n",
    "zero_norm = axs[0].plot([0,0],[0, 0],'g-',[0, 0],[0,0],'g-')\n",
    "\n",
    "for i in range(4):    \n",
    "    axs[i].plot(x1,(1-x1)/2)\n",
    "    axs[i].set_xlim((-1,1))\n",
    "    axs[i].set_ylim((-1,1))\n",
    "    axs[i].set_aspect('equal')\n",
    "    axs[i].set_xlabel('$x_1$')\n",
    "    axs[i].set_title(title_list[i])\n",
    "    axs[i].grid(True)\n",
    "    \n",
    "    tx,ty=zip(pnt_list[i])\n",
    "    lines_list.append(axs[i].plot(tx,ty,'rs'))\n",
    "    lines_list[i][0].set_marker(' ')\n",
    "\n",
    "    dp = tuple(map(sum, zip(pnt_list[i], (0.05,0.05))))\n",
    "    anno_list.append(axs[i].annotate(annos[i],dp))\n",
    "    anno_list[i].set_visible(False)      \n",
    "\n",
    "def update(change):\n",
    "    zero_norm[0].set_data([-sp_space[0][change.new], sp_space[0][change.new]],[0, 0])\n",
    "    zero_norm[1].set_data([0, 0],[-sp_space[0][change.new], sp_space[0][change.new]])\n",
    "    \n",
    "    blen=sqrt(sp_space[0][change.new]**2+sp_space[0][change.new]**2)\n",
    "    axs[1].patches = []\n",
    "    axs[1].add_patch(Rectangle((0,-sp_space[0][change.new]),blen,blen,45,color='g',alpha=0.1))\n",
    "    \n",
    "    axs[2].patches = []\n",
    "    axs[2].add_patch(Circle((0,0),sp_space[2][change.new],color='g',alpha=0.1))\n",
    "    \n",
    "    axs[3].patches = []\n",
    "    axs[3].add_patch(Rectangle((-sp_space[3][change.new],-sp_space[3][change.new]),2*sp_space[3][change.new],2*sp_space[3][change.new],0,color='g',alpha=0.1))   \n",
    "    \n",
    "    if change.new > 95:                      \n",
    "        for i in range(4):\n",
    "            lines_list[i][0].set_marker('s')\n",
    "            anno_list[i].set_visible(True)\n",
    "    else:\n",
    "        for i in range(4):\n",
    "            lines_list[i][0].set_marker(' ')\n",
    "            anno_list[i].set_visible(False)\n",
    "    \n",
    "play = widgets.Play(\n",
    "    interval=50,\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description=\"Press play\",\n",
    "    disabled=False\n",
    ")\n",
    "play.observe(update, 'value')\n",
    "\n",
    "slider = widgets.IntSlider()\n",
    "widgets.jslink((play, 'value'), (slider, 'value'))\n",
    "widgets.HBox([play, slider])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Reconstruction Example\n",
    "We now look at asimple example to showcase reconstruction algorithms. Here, we use a random Gaussian matrix of dimension $m\\times n$ to subsample and mix the sparse input $\\mathbf{x}$. The input is simply 5 non-zero elements set to 1 to make the illustration simple. You can change this easily to random numbers and play around with the parameters. To avoid hard to read plots, we only add a very small amount of noise $\\mathbf{n}$ to get the measurements $\\mathbf{y}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf57bfbcce3d4fb08159f311a3454b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, '$\\\\mathbf{y}$')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy.linalg as npl\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "\n",
    "import fastmat as fm\n",
    "import fastmat.algorithms as fma\n",
    "\n",
    "# sample number\n",
    "m = 25 \n",
    "\n",
    "# sample dimension\n",
    "n = 100\n",
    "\n",
    "# sparsity\n",
    "K = 5\n",
    "\n",
    "# noise level\n",
    "snr = 30           # SNR in dB\n",
    "\n",
    "# define vector matrix shapes for consistency\n",
    "x_shape = (n,)   # Shape of x matrix\n",
    "y_shape = (m,)   # Shape of y matrix = shape of y matrix\n",
    "A_shape = (m,n)   # Shape of A matrix\n",
    "\n",
    "# Generate the random input the probabilist way...\n",
    "#x_mean_on = 0     # mean for the on components\n",
    "#x_var_on = 1      # variance for the on components\n",
    "#x_on = npr.normal(x_mean_on, np.sqrt(x_var_on), xshape)\n",
    "#x_on = np.ones(xshape)\n",
    "#u = np.random.uniform(0, 1, x) < prob_on\n",
    "#x = x_on*u\n",
    "\n",
    "# create the ground truth\n",
    "x = np.zeros(n)\n",
    "x[npr.choice(range(n), K, replace=0)] = 1 #npr.randn(K)\n",
    "#x = np.append(np.random.rand(K), np.zeros(n-K))\n",
    "\n",
    "# Random subsampling matrix\n",
    "A = npr.normal(0,1/np.sqrt(m),A_shape)\n",
    "\n",
    "# Measurements without noise\n",
    "y0 = A.dot(x)\n",
    "\n",
    "## Generate Gaussian noise\n",
    "yvar = np.mean(np.abs(y0)**2)\n",
    "noise_var = yvar*np.power(10, -0.1*snr)\n",
    "noise = npr.normal(0,np.sqrt(noise_var), y_shape)\n",
    "\n",
    "# Add noise to measurements\n",
    "y = y0 + noise\n",
    "\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = False\n",
    "fig.canvas.resizable = False\n",
    "fig.set_figwidth(12)\n",
    "fig.tight_layout()\n",
    "ax1.stem(x,use_line_collection=True)\n",
    "ax1.set_title('$\\mathbf{x}$')\n",
    "ax2.stem(np.dot(A,x),use_line_collection=True)\n",
    "ax2.set_title('$\\mathbf{A}\\mathbf{x}$')\n",
    "ax3.stem(y,use_line_collection=True)\n",
    "ax3.set_title('$\\mathbf{y}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex Relaxation\n",
    "First, we take a look at convex relaxation approaches with efficient solvers. The LASSO and Dantzig solvers are from the pacakge [Primal](https://github.com/ShenQianli/primal). The provided algorithms solve both problems for multiple $\\lambda$, which is illustrated in the following by an interactive figure. Just change the slider to see how the reconstruction result changes with the parameter.\n",
    "### BPDN / LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367522cff51847c2930c484b643542c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544c25bd4b12460391fc4f67a36f4cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='$\\\\lambda$-index', max=77), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.draw_result(ind)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from pyprimal import CompressedSensing\n",
    "\n",
    "solver = CompressedSensing(A, y)\n",
    "solver.train()\n",
    "result = solver.coef()\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = True\n",
    "fig.canvas.resizable = False\n",
    "fig.suptitle('Reconstruction with variable $\\lambda$')\n",
    "fig.set_figwidth(12)\n",
    "ax1.stem(x,use_line_collection=True)\n",
    "for a in x.nonzero()[0]:\n",
    "    ax1.annotate(str(a),(a-1.5,1.012))\n",
    "ax2.set_title(\"$\\lambda=\" + str(result['lambda_list'][0]) + \"$\")\n",
    "\n",
    "def draw_result(ind):    \n",
    "    ax2.clear()\n",
    "    ax2.set_title(\"$\\lambda=\" + str(result['lambda_list'][ind]) + \"$\")    \n",
    "    ax2.stem(result['theta_list'][ind],use_line_collection=True)\n",
    "    \n",
    "interact(draw_result, ind = widgets.IntSlider(description='$\\lambda$-index',\n",
    "                                              value=0,\n",
    "                                              min=0,\n",
    "                                              max=len(result['theta_list'])-1,\n",
    "                                              step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Dantzig selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e10f280d3d94497acf09495a3c881c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ab4578978a40ce9c00259135c34391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='$\\\\lambda$-index', max=99), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.draw_result(ind)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from pyprimal import Dantzig\n",
    "\n",
    "solver = Dantzig(A, y)\n",
    "solver.train()\n",
    "result = solver.coef()\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = True\n",
    "fig.canvas.resizable = False\n",
    "fig.suptitle('Reconstruction with variable $\\lambda$')\n",
    "fig.set_figwidth(12)\n",
    "ax1.stem(x,use_line_collection=True)\n",
    "for a in x.nonzero()[0]:\n",
    "    ax1.annotate(str(a),(a-1.5,1.012))\n",
    "ax2.set_title(\"$\\lambda=\" + str(result['lambda_list'][0]) + \"$\")\n",
    "\n",
    "def draw_result(ind):    \n",
    "    ax2.clear()\n",
    "    ax2.set_title(\"$\\lambda=\" + str(result['lambda_list'][ind]) + \"$\")    \n",
    "    ax2.stem(result['theta_list'][ind],use_line_collection=True)\n",
    "    \n",
    "interact(draw_result, ind = widgets.IntSlider(description='$\\lambda$-index',\n",
    "                                              value=0,\n",
    "                                              min=0,\n",
    "                                              max=len(result['theta_list'])-1,\n",
    "                                              step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Algorithms\n",
    "Again, we use the [fastmat](https://github.com/EMS-TU-Ilmenau/fastmat) package for OMP illustration. Now, the number of iterations determines the number of non-zeros entries in the solution directly. By changing the slider, you can vary the number of iterations / non-zeros and take a look at the reconstruction quality.\n",
    "### OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bfc3f6374c434188724b92a0eabc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6e03197c394f73927ee82333f9f7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='$K$', min=1), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.draw_result(ind)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct it\n",
    "A_fm=fm.Matrix(A)\n",
    "omp = fma.OMP(A_fm, numMaxSteps=1)\n",
    "x_tilde = omp.process(y)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = True\n",
    "fig.canvas.resizable = False\n",
    "fig.suptitle('Reconstruction over different $\\\\alpha$')\n",
    "fig.set_figwidth(12)\n",
    "ax1.stem(x,use_line_collection=True)\n",
    "for a in x.nonzero()[0]:\n",
    "    ax1.annotate(str(a),(a-1.5,1.012))\n",
    "ax2.set_title('$K='+str(K)+'$')\n",
    "\n",
    "def draw_result(ind):    \n",
    "    ax2.clear()\n",
    "    ax2.set_title('$K=' + str(ind) + '$')\n",
    "    omp = fma.OMP(A_fm, numMaxSteps=ind)\n",
    "    x_tilde = omp.process(y)\n",
    "    ax2.stem(x_tilde,use_line_collection=True)\n",
    "        \n",
    "interact(draw_result, ind = widgets.IntSlider(description='$K$',\n",
    "                                              value=1,\n",
    "                                              min=1,\n",
    "                                              max=n,\n",
    "                                              step=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Thresholding\n",
    "Next is the class of thresholding algorithms. Here, we use the package [fastmat](https://github.com/EMS-TU-Ilmenau/fastmat). The package also provides advanced Thresholding algorithms, but for the sake of illustration we just show the ISTA algorithm here. Comparable to the illustrations before, we now can play with the threshold of the soft thresholding function by moving the slider to observe the reconstructed vector.\n",
    "### Soft Thresholding (ISTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85dc380b2444bd19ef6ca94328bb572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847c0a41e7ff4f1ba780d1585a0516c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.01, description='$\\\\alpha$', max=2.0, step=0.001), Output()), _dom_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.draw_result(ind)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "A_fm=fm.Matrix(A)\n",
    "ista = fma.ISTA(A_fm, numLambda = 0.01, numMaxSteps = 1000)\n",
    "x_tilde = ista.process(y)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = True\n",
    "fig.canvas.resizable = False\n",
    "fig.suptitle('Reconstruction over different $\\\\alpha$')\n",
    "fig.set_figwidth(12)\n",
    "ax1.stem(x,use_line_collection=True)\n",
    "for a in x.nonzero()[0]:\n",
    "    ax1.annotate(str(a),(a-1.5,1.012))\n",
    "ax2.set_title('$\\\\alpha$')\n",
    "\n",
    "def draw_result(ind):    \n",
    "    ax2.clear()\n",
    "    ax2.set_title('$\\\\alpha=' + str(ind) + '$')\n",
    "    ista = fma.ISTA(A_fm, numLambda = ind, numMaxSteps = 1000)\n",
    "    x_tilde = ista.process(y)\n",
    "    ax2.stem(x_tilde,use_line_collection=True)\n",
    "    \n",
    "interact(draw_result, ind = widgets.FloatSlider(description='$\\\\alpha$',\n",
    "                                              value=0.01,\n",
    "                                              min=0,\n",
    "                                              max=2,\n",
    "                                              step=.001))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Bayesian Approaches\n",
    "To show the AMP algorithm, we use the [Vampyre](https://github.com/GAMPTeam/vampyre) package that implements an advanced version of AMP called Generalized Approximate Message Passing (GAMP). For the purpose of this illustration, however, it is identical to AMP.\n",
    "\n",
    "To fit the probalistic model to the solver, we use a discrete prior with $P_0$ as $k/n$ to model the mean number of non-zero entries approximately.\n",
    "### Approximate Message Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est0: Input (Mixture) shape: (100,)\n",
      "est1: Output (GaussEst) shape: (25,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae7d1805abe4694a8d8ae2974398551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30da6c01fe40449ab0f9690a7b2a2afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Iteration', max=19), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.draw_result(ind)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import vampyre as vp\n",
    "\n",
    "# Define required parameters for the solver that are not used in the non-probablist data model\n",
    "x_mean_on = 0     # mean for the on components\n",
    "x_var_on = 1      # variance for the on components\n",
    "prob_on = K/n      # fraction of components that are *on*\n",
    "\n",
    "nit = 20  # number of iterations\n",
    "\n",
    "# define the priors to be mixed (Bernoulli + Gaussian)\n",
    "est0_off = vp.estim.DiscreteEst(0,1,x_shape)\n",
    "est0_on = vp.estim.GaussEst(x_mean_on, x_var_on,x_shape)\n",
    "                   \n",
    "# Define the mixed prior\n",
    "est_list = [est0_off, est0_on]\n",
    "pz0 = np.array([1-prob_on, prob_on])\n",
    "est0 = vp.estim.MixEst(est_list, w=pz0, name='Input')\n",
    "\n",
    "# We next define the operator A. In this case the operator is defined by a matrix so we use the MatrixLT class.\n",
    "Aop = vp.trans.MatrixLT(A,x_shape)\n",
    "\n",
    "# describe the likelihood function, p(y|z1). Since y=z1+w, we can describe this as a Gaussian estimator.\n",
    "est1  = vp.estim.GaussEst(y,noise_var,y_shape,name='Output')\n",
    "\n",
    "# Create the solver\n",
    "solver = vp.solver.Gamp(est0,est1,Aop,hist_list=['z0', 'zvar0'],nit=nit)\n",
    "solver.summary()\n",
    "solver.solve()\n",
    "x_hat=solver.z0\n",
    "x_history=solver.hist_dict['z0']\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = True\n",
    "fig.canvas.resizable = False\n",
    "fig.suptitle('Reconstruction over iterations')\n",
    "fig.set_figwidth(12)\n",
    "ax1.stem(x,use_line_collection=True)\n",
    "for a in x.nonzero()[0]:\n",
    "    ax1.annotate(str(a),(a-1.5,1.012))\n",
    "ax2.set_title(\"$Iteration 0\")\n",
    "\n",
    "def draw_result(ind):    \n",
    "    ax2.clear()\n",
    "    ax2.set_title(\"Iteration \" + str(ind))\n",
    "    ax2.stem(x_history[ind],use_line_collection=True)\n",
    "    \n",
    "interact(draw_result, ind = widgets.IntSlider(description='Iteration',\n",
    "                                              value=0,\n",
    "                                              min=0,\n",
    "                                              max=len(x_history)-1,\n",
    "                                              step=1))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
